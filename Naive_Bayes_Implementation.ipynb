{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Naive Bayes Implementation </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> In this assignment Machine Learning Algorithms such as Naive Bayes and K Nearest Neigbors are implemented and tested </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataframe(filename=\"irisTraining.txt\",header=None,delimiter=\" \"):\n",
    "    \"\"\"This function reads the data from given files and return a pandas datafram object.\n",
    "    \n",
    "    Args:\n",
    "        filename(string): The name of file that contains dataset\n",
    "        header: Header of the file\n",
    "        delimiter(string): the character that sperates columns of data\n",
    "    Returns:\n",
    "        pandas dataframe: A pandas datafram object containing the data from the filename\n",
    "    \"\"\"\n",
    "    dataframe_df = pd.read_csv(filename,sep=delimiter,header=header) #read files\n",
    "    return dataframe_df #return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.9</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.9</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.6</td>\n",
       "      <td>-1.9</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>-1.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.0</td>\n",
       "      <td>-1.2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>7.4</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>6.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>4.9</td>\n",
       "      <td>-1.4</td>\n",
       "      <td>-1.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>7.0</td>\n",
       "      <td>-1.2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5.5</td>\n",
       "      <td>-1.4</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>6.3</td>\n",
       "      <td>-1.3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0    1    2    3  4\n",
       "0   5.9 -1.0  4.2  1.5  1\n",
       "1   6.9 -1.1  4.9  1.5  1\n",
       "2   6.6 -1.9  4.6  1.3  1\n",
       "3   4.6 -1.2  1.4  0.2 -1\n",
       "4   6.0 -1.2  4.0  1.0  1\n",
       "..  ...  ...  ...  ... ..\n",
       "95  7.4 -1.8  6.1  1.9 -1\n",
       "96  4.9 -1.4 -1.3  1.0  1\n",
       "97  7.0 -1.2  4.7  1.4  1\n",
       "98  5.5 -1.4 -1.7  1.0  1\n",
       "99  6.3 -1.3  4.7  1.6  1\n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_train_df = get_dataframe(filename=\"datasets/irisTraining.txt\",header=None,delimiter=\" \")\n",
    "iris_train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of Naive Bayes Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_prior_probabilities(dataset_df):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    columns = dataset_df.columns\n",
    "    label_column = columns[len(columns)-1]\n",
    "    labels = dataset_df[label_column].to_numpy()\n",
    "    unique_labels = set(labels)\n",
    "    total_count = len(labels)\n",
    "    prior_probabilities = {}\n",
    "    \n",
    "    for label in unique_labels:\n",
    "        label_count = len(labels[labels==label])\n",
    "        prior = label_count / total_count\n",
    "        log_prior = np.log(prior)\n",
    "        prior_probabilities[label] = [prior,log_prior]\n",
    "        \n",
    "    return prior_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: [0.34, -1.0788096613719298], -1: [0.66, -0.4155154439616658]}\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "prior_probalitites = calculate_prior_probabilities(dataset_df=iris_train_df)\n",
    "print(prior_probalitites)\n",
    "%time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianNaiveBayes():\n",
    "    def __init__(self):\n",
    "        self.__features_mean = {}\n",
    "        self.__features_sdevs = {}\n",
    "        self.__unique_labels = []\n",
    "        self.__trainset_df = None\n",
    "        self.__prior_probabilities = {}\n",
    "        \n",
    "    def fit(self,train_data_df):\n",
    "        \"\"\" THis function computes gaussian likehood \n",
    "        \"\"\"\n",
    "        #set train set for model\n",
    "        self.__trainset_df = train_data_df.copy()\n",
    "        \n",
    "        #  label column\n",
    "        label_column = list(self.__trainset_df.columns)\n",
    "        label_column = label_column[len(label_column)-1]\n",
    "        labels = train_data_df[label_column].to_numpy() #get labels for prior cacluations\n",
    "        total_count = len(labels)\n",
    "        \n",
    "        # get list of class labels\n",
    "        self.__unique_labels = set(self.__trainset_df[label_column])\n",
    "        \n",
    "        #caclulate gaussian parameters\n",
    "        for label in self.__unique_labels:\n",
    "            \n",
    "            # calcuate means and standard deviations\n",
    "            self.__features_mean[label] = list(self.__trainset_df[self.__trainset_df[label_column]==label].mean()) #get mean for specified classlabel  \n",
    "            self.__features_sdevs[label] = list(self.__trainset_df[self.__trainset_df[label_column]==label].std()) #get standard deviation for specified classlabel    \n",
    "    \n",
    "            #mean and standard deviation for label coumn is not required so drop then\n",
    "            self.__features_mean[label].pop()\n",
    "            self.__features_sdevs[label].pop()\n",
    "            \n",
    "            #prior probabity calculations\n",
    "            label_count = len(labels[labels==label])\n",
    "            prior = (label_count * 1.0) / (total_count * 1.0)\n",
    "            self.__prior_probabilities[label] = prior\n",
    "\n",
    "\n",
    "    def print_model_parameters(self):\n",
    "        print(\"Classes: \",self.__unique_labels)\n",
    "        print(\"\")\n",
    "        print(\"Means : \", self.__features_mean)\n",
    "        print(\"\")\n",
    "        print(\"Standard Deviations: \",self.__features_sdevs)\n",
    "        print(\"\")\n",
    "        print(\"Prior Probabilities: \", self.__prior_probabilities)\n",
    "        \n",
    "    \n",
    "    def predict_probabilities(self,test_set_df):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        column_names = test_set_df.columns\n",
    "        label_column = len(column_names) - 1\n",
    "        feature_matrix = test_set_df.drop([label_column],axis=1)\n",
    "        feature_matrix = feature_matrix.to_numpy()\n",
    "        labels_list = []\n",
    "        probabilities = []\n",
    "        \n",
    "        # calculate gaussain likelihoods\n",
    "        for label in self.__unique_labels:\n",
    "            cur_matrix = feature_matrix - np.array(self.__features_mean[label])\n",
    "            cur_matrix = cur_matrix **2\n",
    "            cur_matrix = cur_matrix / (2 * (np.array(self.__features_sdevs[label])**2) )\n",
    "            cur_matrix = np.exp((-1 * cur_matrix))\n",
    "            cur_matrix = cur_matrix * (1.0/np.sqrt(2*np.pi*(np.array(self.__features_sdevs[label]))))\n",
    "            \n",
    "            if cur_matrix.ndim > 1:\n",
    "                cur_matrix = np.prod(cur_matrix,axis=1)\n",
    "            else:\n",
    "                cur_matrix = np.prod(cur_matrix)\n",
    "            \n",
    "            #multiply by prior probabilities\n",
    "            #cur_matrix = cur_matrix * self.__prior_probabilities[label]\n",
    "            \n",
    "            labels_list.append(label)\n",
    "            probabilities.append(cur_matrix)\n",
    "        \n",
    "        # make probabilities into single dataframe\n",
    "        probabilities_df = pd.DataFrame(probabilities) #convert to dataframe\n",
    "        probabilities_df = probabilities_df.transpose()\n",
    "        probabilities_df.columns = labels_list #add labels\n",
    "        return probabilities_df\n",
    "    \n",
    "    def predict_labels(self,test_set_df):\n",
    "        probabilities_df = self.predict_probabilities(test_set_df)\n",
    "        labels_list = probabilities_df.columns\n",
    "        probabilities_df = probabilities_df.to_numpy()\n",
    "        max_index = np.argmax(probabilities_df,axis=1) #get maximum of each row, axis= 1 horizontal, max each row\n",
    "        return np.array(labels_list[max_index])\n",
    "        \n",
    "    def evaluate(self,test_set_df):\n",
    "        column_names = test_set_df.columns\n",
    "        label_column = len(column_names) - 1\n",
    "        actual_labels = test_set_df[label_column].to_numpy()\n",
    "        predicted_labels = self.predict_labels(test_set_df)\n",
    "        agreement =  ( (1.0 * sum(actual_labels == predicted_labels)) / (1.0 * len(predicted_labels)) ) * 100\n",
    "        print(\"Model Accuracy: %0.3f%%\"%agreement)\n",
    "        return agreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GaussianNaiveBayes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(iris_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes:  {1, -1}\n",
      "\n",
      "Means :  {1: [5.847058823529412, -1.388235294117647, 3.005882352941176, 1.3], -1: [5.771212121212121, -1.3181818181818181, 3.548484848484849, 0.22272727272727275]}\n",
      "\n",
      "Standard Deviations:  {1: [0.5124127681076908, 0.3198150089171844, 2.5404534523024638, 0.21602468994692867], -1: [0.9419725868157492, 0.7743799685324615, 2.080328555725489, 1.091617776801647]}\n",
      "\n",
      "Prior Probabilities:  {1: 0.34, -1: 0.66}\n"
     ]
    }
   ],
   "source": [
    "model.print_model_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0    1    2    3  4\n",
      "0  5.9 -1.0  4.2  1.5  1\n",
      "1  6.9 -1.1  4.9  1.5  1\n",
      "2  6.6 -1.9  4.6  1.3  1\n",
      "3  4.6 -1.2  1.4  0.2 -1\n",
      "4  6.0 -1.2  4.0  1.0  1\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>-1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.345609e-02</td>\n",
       "      <td>0.008605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.361666e-03</td>\n",
       "      <td>0.003767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.550744e-03</td>\n",
       "      <td>0.005450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.050555e-09</td>\n",
       "      <td>0.005267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.399215e-02</td>\n",
       "      <td>0.014317</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              1        -1\n",
       "0  2.345609e-02  0.008605\n",
       "1  3.361666e-03  0.003767\n",
       "2  6.550744e-03  0.005450\n",
       "3  7.050555e-09  0.005267\n",
       "4  2.399215e-02  0.014317"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sindex = 0\n",
    "eindex = 5\n",
    "test = iris_train_df.iloc[sindex:eindex]\n",
    "print(test)\n",
    "print(\"\")\n",
    "df = model.predict_probabilities(test)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1, -1,  1, -1,  1], dtype=int64)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_labels(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 95.000%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "95.0"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(iris_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_test_df = get_dataframe(filename=\"datasets/irisTesting.txt\",header=None,delimiter=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 98.000%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "98.0"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(iris_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  1, -1, -1,  1, -1, -1, -1, -1, -1,  1, -1,  1, -1,  1, -1, -1,\n",
       "        1, -1,  1, -1, -1,  1,  1, -1, -1,  1, -1,  1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1,  1, -1,  1, -1, -1,  1,  1, -1, -1,  1, -1, -1, -1],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_labels(iris_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  1, -1, -1,  1, -1, -1, -1, -1, -1,  1, -1,  1, -1,  1, -1, -1,\n",
       "       -1, -1,  1, -1, -1,  1,  1, -1, -1,  1, -1,  1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1,  1, -1,  1, -1, -1,  1,  1, -1, -1,  1, -1, -1, -1],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_test_df[4].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
