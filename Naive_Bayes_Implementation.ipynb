{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Naive Bayes Implementation </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> In this assignment Machine Learning Algorithms such as Naive Bayes and K Nearest Neigbors are implemented and tested </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataframe(filename=\"irisTraining.txt\",header=None,delimiter=\" \"):\n",
    "    \"\"\"This function reads the data from given files and return a pandas datafram object.\n",
    "    \n",
    "    Args:\n",
    "        filename(string): The name of file that contains dataset\n",
    "        header: Header of the file\n",
    "        delimiter(string): the character that sperates columns of data\n",
    "    Returns:\n",
    "        pandas dataframe: A pandas datafram object containing the data from the filename\n",
    "    \"\"\"\n",
    "    dataframe_df = pd.read_csv(filename,sep=delimiter,header=header) #read files\n",
    "    return dataframe_df #return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.9</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.9</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.6</td>\n",
       "      <td>-1.9</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>-1.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.0</td>\n",
       "      <td>-1.2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>7.4</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>6.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>4.9</td>\n",
       "      <td>-1.4</td>\n",
       "      <td>-1.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>7.0</td>\n",
       "      <td>-1.2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5.5</td>\n",
       "      <td>-1.4</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>6.3</td>\n",
       "      <td>-1.3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0    1    2    3  4\n",
       "0   5.9 -1.0  4.2  1.5  1\n",
       "1   6.9 -1.1  4.9  1.5  1\n",
       "2   6.6 -1.9  4.6  1.3  1\n",
       "3   4.6 -1.2  1.4  0.2 -1\n",
       "4   6.0 -1.2  4.0  1.0  1\n",
       "..  ...  ...  ...  ... ..\n",
       "95  7.4 -1.8  6.1  1.9 -1\n",
       "96  4.9 -1.4 -1.3  1.0  1\n",
       "97  7.0 -1.2  4.7  1.4  1\n",
       "98  5.5 -1.4 -1.7  1.0  1\n",
       "99  6.3 -1.3  4.7  1.6  1\n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_train_df = get_dataframe(filename=\"datasets/irisTraining.txt\",header=None,delimiter=\" \")\n",
    "iris_train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of Gaussian Naive Bayes Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianNaiveBayes():\n",
    "    def __init__(self):\n",
    "        self.__features_mean = {}\n",
    "        self.__features_sdevs = {}\n",
    "        self.__unique_labels = []\n",
    "        self.__trainset_df = None\n",
    "        self.__prior_probabilities = {}\n",
    "        \n",
    "    def get_labels(self):\n",
    "        return self.__unique_labels\n",
    "    \n",
    "    def fit(self,train_data_df):\n",
    "        \"\"\" THis function computes gaussian likehood \n",
    "        \"\"\"\n",
    "        #set train set for model\n",
    "        self.__trainset_df = train_data_df.copy()\n",
    "        \n",
    "        #  label column\n",
    "        label_column = list(self.__trainset_df.columns)\n",
    "        label_column = label_column[len(label_column)-1]\n",
    "        labels = train_data_df[label_column].to_numpy() #get labels for prior cacluations\n",
    "        total_count = len(labels)\n",
    "        \n",
    "        # get list of class labels\n",
    "        self.__unique_labels = set(self.__trainset_df[label_column])\n",
    "        \n",
    "        #caclulate gaussian parameters\n",
    "        for label in self.__unique_labels:\n",
    "            \n",
    "            # calcuate means and standard deviations\n",
    "            self.__features_mean[label] = list(self.__trainset_df[self.__trainset_df[label_column]==label].mean()) #get mean for specified classlabel  \n",
    "            self.__features_sdevs[label] = list(self.__trainset_df[self.__trainset_df[label_column]==label].std()) #get standard deviation for specified classlabel    \n",
    "    \n",
    "            #mean and standard deviation for label coumn is not required so drop then\n",
    "            self.__features_mean[label].pop()\n",
    "            self.__features_sdevs[label].pop()\n",
    "            \n",
    "            #prior probabity calculations\n",
    "            label_count = len(labels[labels==label])\n",
    "            prior = (label_count * 1.0) / (total_count * 1.0)\n",
    "            self.__prior_probabilities[label] = prior\n",
    "\n",
    "\n",
    "    def print_model_parameters(self):\n",
    "        print(\"Classes: \",self.__unique_labels)\n",
    "        print(\"\")\n",
    "        print(\"Means : \", self.__features_mean)\n",
    "        print(\"\")\n",
    "        print(\"Standard Deviations: \",self.__features_sdevs)\n",
    "        print(\"\")\n",
    "        print(\"Prior Probabilities: \", self.__prior_probabilities)\n",
    "        \n",
    "    \n",
    "    def predict_probabilities(self,test_set_df):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        column_names = test_set_df.columns\n",
    "        label_column = len(column_names) - 1\n",
    "        feature_matrix = test_set_df.drop([label_column],axis=1)\n",
    "        feature_matrix = feature_matrix.to_numpy()\n",
    "        labels_list = []\n",
    "        probabilities = []\n",
    "        \n",
    "        # calculate gaussain likelihoods\n",
    "        for label in self.__unique_labels:\n",
    "            cur_matrix = feature_matrix - np.array(self.__features_mean[label])\n",
    "            cur_matrix = cur_matrix **2\n",
    "            cur_matrix = cur_matrix / (2 * (np.array(self.__features_sdevs[label])**2) )\n",
    "            cur_matrix = np.exp((-1 * cur_matrix))\n",
    "            cur_matrix = cur_matrix * (1.0/np.sqrt(2*np.pi*(np.array(self.__features_sdevs[label]))))\n",
    "            \n",
    "            if cur_matrix.ndim > 1:\n",
    "                cur_matrix = np.prod(cur_matrix,axis=1)\n",
    "            else:\n",
    "                cur_matrix = np.prod(cur_matrix)\n",
    "            \n",
    "            #multiply by prior probabilities\n",
    "            cur_matrix = cur_matrix * self.__prior_probabilities[label]\n",
    "            \n",
    "            labels_list.append(label)\n",
    "            probabilities.append(cur_matrix)\n",
    "        \n",
    "        # make probabilities into single dataframe\n",
    "        probabilities_df = pd.DataFrame(probabilities) #convert to dataframe\n",
    "        probabilities_df = probabilities_df.transpose()\n",
    "        probabilities_df.columns = labels_list #add labels\n",
    "        return probabilities_df\n",
    "    \n",
    "    def predict_labels(self,test_set_df):\n",
    "        probabilities_df = self.predict_probabilities(test_set_df)\n",
    "        labels_list = probabilities_df.columns\n",
    "        probabilities_df = probabilities_df.to_numpy()\n",
    "        max_index = np.argmax(probabilities_df,axis=1) #get maximum of each row, axis= 1 horizontal, max each row\n",
    "        return np.array(labels_list[max_index])\n",
    "        \n",
    "    def evaluate(self,test_set_df):\n",
    "        column_names = test_set_df.columns\n",
    "        label_column = len(column_names) - 1\n",
    "        actual_labels = test_set_df[label_column].to_numpy()\n",
    "        predicted_labels = self.predict_labels(test_set_df)\n",
    "        #print(\"1\",len(predicted_labels[predicted_labels==1]))\n",
    "        #print(\"-1\",len(predicted_labels[predicted_labels==-1]))\n",
    "        agreement =  ( (1.0 * sum(actual_labels == predicted_labels)) / (1.0 * len(predicted_labels)) ) * 100\n",
    "        print(\"Model Accuracy: %0.3f%%\"%agreement)\n",
    "        return agreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GaussianNaiveBayes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(iris_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes:  {1, -1}\n",
      "\n",
      "Means :  {1: [5.847058823529412, -1.388235294117647, 3.005882352941176, 1.3], -1: [5.771212121212121, -1.3181818181818181, 3.548484848484849, 0.22272727272727275]}\n",
      "\n",
      "Standard Deviations:  {1: [0.5124127681076908, 0.3198150089171844, 2.5404534523024638, 0.21602468994692867], -1: [0.9419725868157492, 0.7743799685324615, 2.080328555725489, 1.091617776801647]}\n",
      "\n",
      "Prior Probabilities:  {1: 0.34, -1: 0.66}\n"
     ]
    }
   ],
   "source": [
    "model.print_model_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0    1    2    3  4\n",
      "0  5.9 -1.0  4.2  1.5  1\n",
      "1  6.9 -1.1  4.9  1.5  1\n",
      "2  6.6 -1.9  4.6  1.3  1\n",
      "3  4.6 -1.2  1.4  0.2 -1\n",
      "4  6.0 -1.2  4.0  1.0  1\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>-1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.975071e-03</td>\n",
       "      <td>0.005679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.142966e-03</td>\n",
       "      <td>0.002487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.227253e-03</td>\n",
       "      <td>0.003597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.397189e-09</td>\n",
       "      <td>0.003476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.157332e-03</td>\n",
       "      <td>0.009449</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              1        -1\n",
       "0  7.975071e-03  0.005679\n",
       "1  1.142966e-03  0.002487\n",
       "2  2.227253e-03  0.003597\n",
       "3  2.397189e-09  0.003476\n",
       "4  8.157332e-03  0.009449"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sindex = 0\n",
    "eindex = 5\n",
    "test = iris_train_df.iloc[sindex:eindex]\n",
    "print(test)\n",
    "print(\"\")\n",
    "df = model.predict_probabilities(test)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1, -1, -1, -1, -1], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_labels(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 89.000%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "89.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(iris_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  1,  1, -1,  1, -1, -1, -1, -1, -1, -1, -1,  1, -1, -1, -1, -1,\n",
       "        1, -1, -1, -1, -1, -1,  1, -1, -1,  1, -1, -1, -1, -1, -1, -1,  1,\n",
       "        1,  1,  1, -1,  1, -1,  1,  1, -1, -1,  1, -1, -1,  1, -1, -1,  1,\n",
       "       -1, -1, -1, -1, -1, -1, -1,  1,  1, -1, -1, -1, -1,  1,  1, -1, -1,\n",
       "       -1, -1, -1, -1,  1, -1, -1, -1, -1, -1, -1,  1, -1,  1,  1, -1,  1,\n",
       "        1,  1, -1, -1, -1, -1, -1, -1,  1, -1, -1,  1,  1,  1,  1],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_train_df[4].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  1, -1, -1, -1, -1,\n",
       "        1, -1, -1, -1, -1, -1,  1, -1, -1,  1, -1, -1, -1, -1, -1, -1,  1,\n",
       "        1,  1, -1, -1,  1, -1,  1,  1, -1, -1,  1, -1, -1,  1, -1, -1,  1,\n",
       "       -1, -1, -1, -1, -1, -1, -1,  1,  1,  1, -1, -1, -1,  1,  1, -1, -1,\n",
       "       -1, -1, -1, -1,  1, -1, -1, -1, -1, -1, -1, -1, -1,  1,  1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1,  1,  1, -1,  1, -1,  1,  1],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_labels(iris_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_test_df = get_dataframe(filename=\"datasets/irisTesting.txt\",header=None,delimiter=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 86.000%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "86.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(iris_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1,  1, -1, -1, -1, -1, -1, -1, -1, -1,  1, -1, -1, -1,  1, -1, -1,\n",
       "        1, -1,  1, -1, -1, -1,  1, -1, -1,  1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1,  1, -1,  1, -1, -1,  1, -1, -1, -1,  1, -1, -1, -1],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = model.predict_labels(iris_test_df)\n",
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  1, -1, -1,  1, -1, -1, -1, -1, -1,  1, -1,  1, -1,  1, -1, -1,\n",
       "       -1, -1,  1, -1, -1,  1,  1, -1, -1,  1, -1,  1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1,  1, -1,  1, -1, -1,  1,  1, -1, -1,  1, -1, -1, -1],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual = iris_test_df[4].to_numpy()\n",
    "actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{-1, 1}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_confusion_matrix(actual_labels,predicted_labels):\n",
    "    true_positives = 0\n",
    "    false_negatives = 0\n",
    "    true_negatives = 0\n",
    "    false_positives = 0\n",
    "    for i in range(0,len(actual_labels)):\n",
    "        if actual_labels[i]==1:\n",
    "            if actual_labels[i] == predicted_labels[i]: #1 = 1\n",
    "                true_positives += 1\n",
    "            else: #1 != -1\n",
    "                false_negatives += 1\n",
    "        else: \n",
    "            if actual_labels[i] == predicted_labels[i]: #0 = 0\n",
    "                true_negatives += 1\n",
    "            else: #1 != -1\n",
    "                false_positives += 1\n",
    "    \n",
    "    confusion_matrix = np.squeeze(np.array([[true_positives,false_negatives],[false_positives,true_negatives]]))\n",
    "    #print(cm)\n",
    "    plt.clf()\n",
    "    #plt.imshow(cm, interpolation='nearest', cmap=plt.cm.inferno)\n",
    "    plt.imshow(confusion_matrix, cmap=plt.cm.inferno)\n",
    "    classNames = ['Positive','Negative']\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    tick_marks = np.arange(len(classNames))\n",
    "    plt.xticks(tick_marks, classNames, rotation=45)\n",
    "    plt.yticks(tick_marks, classNames)\n",
    "    s = [['TP','FN'], ['FP', 'TN']]\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            plt.text(j,i,str(s[i][j])+\"=\"+str(confusion_matrix[i][j]),color=\"r\",fontsize=12)\n",
    "    plt.show()\n",
    "    return confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[25,  9],\n",
       "       [ 2, 64]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_confusion_matrix(iris_train_df[4].to_numpy(),model.predict_labels(iris_train_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_aprf(actual_labels,predicted_labels):\n",
    "    true_positives = 0\n",
    "    false_negatives = 0\n",
    "    true_negatives = 0\n",
    "    false_positives = 0\n",
    "    for i in range(0,len(actual_labels)):\n",
    "        if actual_labels[i]==1:\n",
    "            if actual_labels[i] == predicted_labels[i]: #1 = 1\n",
    "                true_positives += 1\n",
    "            else: #1 != -1\n",
    "                false_negatives += 1\n",
    "        else: \n",
    "            if actual_labels[i] == predicted_labels[i]: #0 = 0\n",
    "                true_negatives += 1\n",
    "            else: #1 != -1\n",
    "                false_positives += 1\n",
    "                \n",
    "    accuracy = ((true_positives + true_negatives) *1.0) / (1.0 * (true_positives + true_negatives + false_negatives + false_positives) )\n",
    "    precision = (true_positives * 1.0) / ( (true_positives + false_positives)* 1.0)\n",
    "    recall = (true_positives * 1.0) / ( (true_positives + false_negatives)* 1.0)\n",
    "    f_measure = (2.0 * true_positives) / (1.0 * ( (2.0 * true_positives) + false_positives + false_negatives ) )\n",
    "    print(\"Accuracy: %0.2f\"%accuracy)\n",
    "    print(\"Precision: %0.2f\"%precision)\n",
    "    print(\"Recall: %0.2f\"%recall)\n",
    "    print(\"F-Measure: %0.2f\"%f_measure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.89\n",
      "Precision: 0.93\n",
      "Recall: 0.74\n",
      "F-Measure: 0.82\n"
     ]
    }
   ],
   "source": [
    "binary_aprf(iris_train_df[4].to_numpy(),model.predict_labels(iris_train_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.86\n",
      "Precision: 0.91\n",
      "Recall: 0.62\n",
      "F-Measure: 0.74\n"
     ]
    }
   ],
   "source": [
    "binary_aprf(iris_test_df[4].to_numpy(),model.predict_labels(iris_test_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of Categorical Naive Bayes Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0  1  2  3  4\n",
       "0   1  3  2  1 -1\n",
       "1   1  3  2  2 -1\n",
       "2   2  3  2  1  1\n",
       "3   3  2  2  1  1\n",
       "4   3  1  1  1  1\n",
       "5   3  1  1  2 -1\n",
       "6   2  1  1  2  1\n",
       "7   1  2  2  1 -1\n",
       "8   1  1  1  1  1\n",
       "9   3  2  1  1  1\n",
       "10  1  2  1  2  1\n",
       "11  2  2  2  2  1\n",
       "12  2  3  1  1  1\n",
       "13  3  1  2  2 -1"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buy_train_df = get_dataframe(filename=\"datasets/buyTraining.txt\",header=None,delimiter=\" \")\n",
    "buy_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_freq_corpus(dataframe_df):\n",
    "    freq_corpus= {}\n",
    "    feature_matrix= buy_train_df.to_numpy()\n",
    "    for i in range(0,feature_matrix.shape[0]):\n",
    "        for j in range(0,feature_matrix.shape[1]-1):\n",
    "            attribute = j\n",
    "            category = feature_matrix[i,j]\n",
    "            label = feature_matrix[i,feature_matrix.shape[1]-1]\n",
    "            key_pair = (attribute,category,label)\n",
    "            if key_pair not in freq_corpus:\n",
    "                freq_corpus[key_pair] = 1\n",
    "            else:\n",
    "                freq_corpus[key_pair] += 1\n",
    "    return freq_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0, 1, -1): 3,\n",
       " (1, 3, -1): 2,\n",
       " (2, 2, -1): 4,\n",
       " (3, 1, -1): 2,\n",
       " (3, 2, -1): 3,\n",
       " (0, 2, 1): 4,\n",
       " (1, 3, 1): 2,\n",
       " (2, 2, 1): 3,\n",
       " (3, 1, 1): 6,\n",
       " (0, 3, 1): 3,\n",
       " (1, 2, 1): 4,\n",
       " (1, 1, 1): 3,\n",
       " (2, 1, 1): 6,\n",
       " (0, 3, -1): 2,\n",
       " (1, 1, -1): 2,\n",
       " (2, 1, -1): 1,\n",
       " (3, 2, 1): 3,\n",
       " (1, 2, -1): 1,\n",
       " (0, 1, 1): 2}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_corpus = build_freq_corpus(buy_train_df)\n",
    "freq_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute label counts\n",
    "unique_labels = set(buy_train_df[4])\n",
    "unique_labels\n",
    "label_frequencies = {}\n",
    "for label in unique_labels:\n",
    "    label_frequencies[label] = len(buy_train_df[buy_train_df[4]==label][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute posterior likelihood\n",
    "feature_matrix= buy_train_df.to_numpy()\n",
    "prior_probabilities = {}\n",
    "for key_pair in freq_corpus.keys():\n",
    "    category_freq = freq_corpus[key_pair]\n",
    "    label_freq = label_frequencies[key_pair[2]]\n",
    "    posterior_prob = (1.0 * category_freq) / (1.0 * label_freq)\n",
    "    prior_probabilities[key_pair] = posterior_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0.])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CategoricalNaiveBayes():\n",
    "    def __init__(self):\n",
    "        self.__unique_labels = ()\n",
    "        self.__label_frequencies = {}\n",
    "        self.__category_frequencies = {}\n",
    "        self.__prior_probabilities = {}\n",
    "        self.__posterior_probabilities = {}\n",
    "        self.__trainset_df = None\n",
    "        \n",
    "    def print_parameters(self):\n",
    "        print(\"Classes: \", self.__unique_labels)\n",
    "        print(\"\")\n",
    "        print(\"Class Frequencies: \",self.__label_frequencies)\n",
    "        print(\"\")\n",
    "        print(\"Category Frequencies: \",self.__category_frequencies)\n",
    "        print(\"\")\n",
    "        print(\"Prior Probabilities: \",self.__prior_probabilities)\n",
    "        print(\"\")\n",
    "        print(\"Posterior Probabilities: \",self.__posterior_probabilities)\n",
    "\n",
    "    def fit(self,train_set_df):\n",
    "        \n",
    "        #compute categorical frequencies\n",
    "        feature_matrix= train_set_df.to_numpy()\n",
    "        for i in range(0,feature_matrix.shape[0]):\n",
    "            for j in range(0,feature_matrix.shape[1]-1):\n",
    "                attribute = j\n",
    "                category = feature_matrix[i,j]\n",
    "                label = feature_matrix[i,feature_matrix.shape[1]-1]\n",
    "                key_pair = (attribute,category,label)\n",
    "                if key_pair not in self.__category_frequencies:\n",
    "                    self.__category_frequencies[key_pair] = 1\n",
    "                else:\n",
    "                    self.__category_frequencies[key_pair] += 1\n",
    "                    \n",
    "        #compute label frequencies and prior probabilities\n",
    "        label_column = list(train_set_df.columns)\n",
    "        label_column = label_column[len(label_column)-1]\n",
    "        self.__unique_labels = list(set(train_set_df[label_column])) # get list of class labels\n",
    "        \n",
    "        for label in self.__unique_labels:\n",
    "            self.__label_frequencies[label] = len(buy_train_df[buy_train_df[4]==label][4])\n",
    "            \n",
    "        #compute posterior likelihood\n",
    "        for key_pair in self.__category_frequencies.keys():\n",
    "            category_freq = self.__category_frequencies[key_pair]\n",
    "            label_freq = self.__label_frequencies[key_pair[2]]\n",
    "            posterior_prob = (1.0 * category_freq) / (1.0 * label_freq)\n",
    "            self.__posterior_probabilities[key_pair] = posterior_prob\n",
    "            \n",
    "        #compute prior probabiilies\n",
    "        total_labels = len(train_set_df[label_column])\n",
    "        for label in self.__unique_labels:\n",
    "            freq = len(buy_train_df[buy_train_df[4]==label][4])\n",
    "            prior_prob = (1.0 * freq) / (total_labels * 1.0)\n",
    "            self.__prior_probabilities[label] = prior_prob\n",
    "            \n",
    "    def predict_probabilities(self,test_set_df):\n",
    "        #get column\n",
    "        label_column = list(test_set_df.columns)\n",
    "        label_column = label_column[len(label_column)-1]\n",
    "        \n",
    "        feature_matrix = test_set_df.to_numpy() #convert to numpy\n",
    "        predicted_probailities = [] #predcited probabilities\n",
    "        for i in range(0,feature_matrix.shape[0]):\n",
    "            row_probs = np.zeros(len(self.__unique_labels))\n",
    "            for j in range(0,feature_matrix.shape[1]-1):\n",
    "                attribute = j\n",
    "                category = feature_matrix[i,j]\n",
    "                label_wise_prob = []\n",
    "                for k in range(0,len(self.__unique_labels)):\n",
    "                    key_pair = (attribute,category,self.__unique_labels[k])\n",
    "                    posterior_prob = self.__posterior_probabilities[key_pair]\n",
    "                    if j == 0:\n",
    "                        row_probs[k] = posterior_prob\n",
    "                    else:\n",
    "                        row_probs[k] *= posterior_prob\n",
    "            predicted_probailities.append(row_probs)\n",
    "            \n",
    "        predicted_probailities = np.squeeze(np.array(predicted_probailities))\n",
    "        predicted_probailities = pd.dataframe(predicted_probailities)\n",
    "        print(predicted_probailities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_model = CategoricalNaiveBayes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H1> Add One to Categorical Freqencies: Laplacian Smoothing </H1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_model.fit(buy_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes:  [1, -1]\n",
      "\n",
      "Class Frequencies:  {1: 9, -1: 5}\n",
      "\n",
      "Category Frequencies:  {(0, 1, -1): 3, (1, 3, -1): 2, (2, 2, -1): 4, (3, 1, -1): 2, (3, 2, -1): 3, (0, 2, 1): 4, (1, 3, 1): 2, (2, 2, 1): 3, (3, 1, 1): 6, (0, 3, 1): 3, (1, 2, 1): 4, (1, 1, 1): 3, (2, 1, 1): 6, (0, 3, -1): 2, (1, 1, -1): 2, (2, 1, -1): 1, (3, 2, 1): 3, (1, 2, -1): 1, (0, 1, 1): 2}\n",
      "\n",
      "Prior Probabilities:  {1: 0.6428571428571429, -1: 0.35714285714285715}\n",
      "\n",
      "Posterior Probabilities:  {(0, 1, -1): 0.6, (1, 3, -1): 0.4, (2, 2, -1): 0.8, (3, 1, -1): 0.4, (3, 2, -1): 0.6, (0, 2, 1): 0.4444444444444444, (1, 3, 1): 0.2222222222222222, (2, 2, 1): 0.3333333333333333, (3, 1, 1): 0.6666666666666666, (0, 3, 1): 0.3333333333333333, (1, 2, 1): 0.4444444444444444, (1, 1, 1): 0.3333333333333333, (2, 1, 1): 0.6666666666666666, (0, 3, -1): 0.4, (1, 1, -1): 0.4, (2, 1, -1): 0.2, (3, 2, 1): 0.3333333333333333, (1, 2, -1): 0.2, (0, 1, 1): 0.2222222222222222}\n"
     ]
    }
   ],
   "source": [
    "cat_model.print_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "(0, 2, -1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-64-1eac5eb06991>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcat_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_probabilities\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuy_train_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-60-73132c0b53a7>\u001b[0m in \u001b[0;36mpredict_probabilities\u001b[1;34m(self, test_set_df)\u001b[0m\n\u001b[0;32m     71\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__unique_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m                     \u001b[0mkey_pair\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mattribute\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcategory\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__unique_labels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m                     \u001b[0mposterior_prob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__posterior_probabilities\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey_pair\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mj\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m                         \u001b[0mrow_probs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mposterior_prob\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: (0, 2, -1)"
     ]
    }
   ],
   "source": [
    "cat_model.predict_probabilities(buy_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
